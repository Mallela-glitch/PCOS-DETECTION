import os
from kaggle.api.kaggle_api_extended import KaggleApi
os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()
api = KaggleApi()
api.authenticate()
dataset = 'anaghachoudhari/pcos-detection-using-ultrasound-images'
download_path = '.'
if not os.path.exists('./pcos_data'):
    print("Downloading dataset from Kaggle...")
    api.dataset_download_files(dataset, path=download_path, unzip=True)
    print("Download complete.")
else:
    print("Dataset already downloaded.")
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from sklearn import preprocessing
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
train_dir = './pcos_data/data/train'
test_dir = './pcos_data/data/test'
X_train, y_train = [], []
X_test, y_test = [], []
def load_images(folder, label, X, y):
    for img_name in tqdm(os.listdir(folder)):
        img_path = os.path.join(folder, img_name)
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.resize(img, (224, 224))
            X.append(img)
            y.append(label)
load_images(os.path.join(train_dir, 'infected'), 'infected', X_train, y_train)
load_images(os.path.join(train_dir, 'notinfected'), 'notinfected', X_train, y_train)
load_images(os.path.join(test_dir, 'infected'), 'infected', X_test, y_test)
load_images(os.path.join(test_dir, 'notinfected'), 'notinfected', X_test, y_test)
def visualize_samples(X, y, num_samples=6):
    plt.figure(figsize=(15, 10))
    for i in range(num_samples):
        plt.subplot(2, num_samples // 2, i + 1)
        plt.imshow(cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB))
        plt.title(y[i])
        plt.axis('off')
    plt.tight_layout()
    plt.show()
visualize_samples(X_train, y_train)
X_train = np.array(X_train) / 255.0
X_test = np.array(X_test) / 255.0
le = preprocessing.LabelEncoder()
y_train_enc = le.fit_transform(y_train)
y_test_enc = le.transform(y_test)
y_train_enc = tf.keras.utils.to_categorical(y_train_enc, 2)
y_test_enc = tf.keras.utils.to_categorical(y_test_enc, 2)
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in base_model.layers:
    layer.trainable = False
def build_model(base, num_classes=2):
    x = base.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dense(512, activation='relu')(x)
    predictions = Dense(num_classes, activation='softmax')(x)
    return Model(inputs=base.input, outputs=predictions)
model = build_model(base_model)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])
print(model.summary())
history = model.fit(X_train, y_train_enc,
                    epochs=10,
                    validation_data=(X_test, y_test_enc),
                    batch_size=32,
                    verbose=1)
if not os.path.exists('saved_model'):
    os.makedirs('saved_model')
model.save('saved_model/pcos_detection_vgg16.h5')
print("âœ… Model saved in saved_model/pcos_detection_vgg16.h5")
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()
